{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9647fb3a-3adf-421a-9fcd-c57d0f2a9b22",
   "metadata": {},
   "source": [
    "### test RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e147265-5979-4785-8537-37d3012b5418",
   "metadata": {},
   "source": [
    "#### Retrieval augmented generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658c36a-2018-4a99-bc35-d4561feb7f3d",
   "metadata": {},
   "source": [
    "[langchain.com](https://www.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633edb3-bf37-4324-8111-cfea598b3a11",
   "metadata": {},
   "source": [
    "```bash\n",
    "uv add langchain langchain_community faiss-cpu sentence-transformers transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93203e-0441-4807-9eea-1c791055f2fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### whole of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949aadbc-7e51-44eb-bf42-e68b38a5cd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading zip file...\n",
      "Download complete!\n",
      "Extracting files...\n",
      "Files extracted to: asia_txt_files\n",
      "Extracted files:\n",
      "['Malaysia.txt', 'Mongolia.txt', 'Philippines.txt', 'South_Korea.txt', 'Thailand.txt', 'Japan.txt', 'Taiwan.txt', 'Indonesia.txt', 'Vietnam.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Answer the following question based on the provided context:\n",
      "Vietnam is a Southeast Asian country known for its rich history, diverse landscapes, and delicious cuisine. Hanoi and Ho Chi Minh City are its major urban centers, each with a unique character. Ha Long Bay’s limestone karsts and the Mekong Delta’s floating markets are famous geographical highlights. Vietnamese culture is deeply influenced by Confucian values, French colonial heritage, and indigenous traditions.\n",
      "\n",
      "Thailand is a Southeast Asian country famous for its tropical beaches, ornate temples, and bustling street food culture. Bangkok, the capital, is known for its vibrant nightlife and historical sites like the Grand Palace and Wat Arun. Northern Thailand features mountainous landscapes and cultural cities like Chiang Mai, while the south offers world-renowned islands such as Phuket and Koh Samui.\n",
      "\n",
      "Malaysia is a diverse country in Southeast Asia, divided into Peninsular Malaysia and Malaysian Borneo. Kuala Lumpur, the capital, features the iconic Petronas Towers. The country is known for its multicultural society, rainforests, and beautiful islands such as Langkawi. Malaysian cuisine blends Malay, Chinese, and Indian influences, making it one of the most flavorful in the region.\n",
      "\n",
      "Japan is an island nation in East Asia, known for its unique blend of ancient traditions and cutting-edge technology. It has a rich cultural heritage, including tea ceremonies, sumo wrestling, and kabuki theater. Geographically, Japan consists of four main islands and numerous smaller ones, featuring mountains, forests, and a rugged coastline. Mount Fuji is its most iconic peak. Major cities include Tokyo, Kyoto, and Osaka, each offering distinct experiences from historical temples to modern skyscrapers.\n",
      "\n",
      "Question: What are the best Asian cuisine dishes?\n",
      "Answer: Asian food is an essential element in a diverse society. This is evident in Thailand's food scene with the high quality, healthful meals many Americans enjoy while abroad. The cuisine is also recognized by other Southeast Asian nations for the country's rich selection of cuisine. As well as its reputation as a \"food exporter\", Southeast Asia is a great place to start your adventure in Southeast Asia. Thailand is one of the most diverse and diverse places in the world, with diverse ethnicities and culture.\n",
      "\n",
      "Question: What are the most amazing restaurants in the world?\n",
      "\n",
      "Answer: Singapore has many amazing restaurants. Bangkok offers the best seafood and seafood from all over the world. In Cambodia, Phnom Penh, Andong and Nusa Tenggang you have a variety of great seafood restaurants, as well as delicious, amazing Korean and Vietnamese dishes. Thailand has many exotic cuisines such as the sika, which is also famous for its wild bird populations. As the country's only\n"
     ]
    }
   ],
   "source": [
    "# uv add ipywidgets\n",
    "\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "zip_url = \"https://github.com/gakudo-ai/open-datasets/raw/refs/heads/main/asia_documents.zip\"\n",
    "zip_path = \"asia_documents.zip\"\n",
    "extract_folder = \"asia_txt_files\"\n",
    "\n",
    "print(\"Downloading zip file...\")\n",
    "urllib.request.urlretrieve(zip_url, zip_path)\n",
    "print(\"Download complete!\")\n",
    "\n",
    "print(\"Extracting files...\")\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"Files extracted to: {extract_folder}\")\n",
    "\n",
    "print(\"Extracted files:\")\n",
    "print(os.listdir(extract_folder))\n",
    "\n",
    "\n",
    "# uv add -U langchain-huggingface\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "folder_path = \"asia_txt_files\"\n",
    "\n",
    "documents = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        loader = TextLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=\"gpt2\", device=0, max_new_tokens=200)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "prompt_template = \"\"\"Answer the following question based on the provided context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},  # Pass the prompt here\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "def truncate_to_max_tokens(text, max_tokens=500):\n",
    "    tokens = text.split()\n",
    "    if len(tokens) > max_tokens:\n",
    "        return \" \".join(tokens[:max_tokens])\n",
    "    return text\n",
    "\n",
    "\n",
    "query = \"What are the best Asian cuisine dishes?\"\n",
    "\n",
    "# Use `invoke` instead of `get_relevant_documents`\n",
    "retrieved_docs = retriever.invoke(query)[:1]  # Top-1 document\n",
    "context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "context = truncate_to_max_tokens(context, max_tokens=500)\n",
    "\n",
    "# Use `invoke` instead of `run`\n",
    "response = retrieval_qa.invoke({\"query\": query})\n",
    "print(\"Answer:\", response[\"result\"])  # Access the result via [\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851bb51d-cda3-4913-a282-01b586a1a456",
   "metadata": {},
   "source": [
    "#### seperate of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07b3fe62-c8e3-46e2-b5e9-5f34094b2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv add ipywidgets\n",
    "\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38c4dd7e-a77c-4bef-aa8d-dd18d9bd591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading zip file...\n",
      "Download complete!\n",
      "Extracting files...\n",
      "Files extracted to: asia_txt_files\n",
      "Extracted files:\n",
      "['Malaysia.txt', 'Mongolia.txt', 'Philippines.txt', 'South_Korea.txt', 'Thailand.txt', 'Japan.txt', 'Taiwan.txt', 'Indonesia.txt', 'Vietnam.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "zip_url = \"https://github.com/gakudo-ai/open-datasets/raw/refs/heads/main/asia_documents.zip\"\n",
    "zip_path = \"asia_documents.zip\"\n",
    "extract_folder = \"asia_txt_files\"\n",
    "\n",
    "print(\"Downloading zip file...\")\n",
    "urllib.request.urlretrieve(zip_url, zip_path)\n",
    "print(\"Download complete!\")\n",
    "\n",
    "print(\"Extracting files...\")\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"Files extracted to: {extract_folder}\")\n",
    "\n",
    "print(\"Extracted files:\")\n",
    "print(os.listdir(extract_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24bfb7e2-a119-42e7-a7ad-d18dfe3a3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv add -U langchain-huggingface\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "folder_path = \"asia_txt_files\"\n",
    "\n",
    "documents = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        loader = TextLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "                    chunk_size=500, \n",
    "                    chunk_overlap=100\n",
    "                    )\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Option 1: Auto-cached (after first download)  ==> this is recomended\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Option 2: Explicit local path                 ==> this is faster\n",
    "# local_model_path = os.path.expanduser(\"~/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf\")\n",
    "# embedding_model_local = HuggingFaceEmbeddings(model_name=local_model_path)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1400836a-632f-4381-9a55-5f482a892fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama models specifically for embeddings/RAG\n",
    "#\n",
    "# 1- nomic-embed-text\n",
    "# 2- mxbai-embed-large\n",
    "# 3- llama3\n",
    "# 4- nomic-embed \n",
    "# 5- all-MiniLM\n",
    "#\n",
    "# \"nomic-embed-text\" is the best ollama model for embedding/RAG\n",
    "\n",
    "# Example:\n",
    "#\n",
    "# from langchain.embeddings import OllamaEmbeddings\n",
    "# embedding_model = OllamaEmbeddings(model_name=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c37b90ca-6531-42ae-9724-95dee7cb3a62",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1749299754.py, line 48)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=\"gpt2\", device=0, max_new_tokens=200)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "\"\"\"\n",
    "                  [1]\n",
    "########################################\n",
    "# For limited GPU memory (8GB or less) #\n",
    "########################################\n",
    "\n",
    "# 4-bit quantized model with better memory efficiency\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Configure quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load a smaller, but powerful model\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"  # Alternative to Llama 2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "                  [2]\n",
    "#####################################\n",
    "# For using Ollama (easiest option) #\n",
    "#####################################\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Simple setup with Ollama - handles all memory management for you\n",
    "llm = Ollama(\n",
    "    model=\"mistral\",  # or \"llama2\", \"llama3\" if available\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# Note: With this approach, you don't need the pipeline creation\n",
    "# The rest of your RAG code can remain the same\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "                      [3]\n",
    "##################################################\n",
    "# Cloud API option if local resource is an issue #\n",
    "##################################################\n",
    "\n",
    "from langchain_openai import ChatOpenAI  # or any other API-based model\n",
    "\n",
    "# No local resources needed\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",  # Or use another API model\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# The rest of your RAG setup remains the same\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a1c24ca-2a6d-4e10-ab99-3d572cc132d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "prompt_template = \"\"\"Answer the following question based on the provided context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},  # Pass the prompt here\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faf6c09a-9ba8-45ff-9ffd-827ec1786acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_to_max_tokens(text, max_tokens=500):\n",
    "    tokens = text.split()\n",
    "    if len(tokens) > max_tokens:\n",
    "        return \" \".join(tokens[:max_tokens])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a9a7827-79d0-481a-b1b8-a1e4d8e891bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Answer the following question based on the provided context:\n",
      "Vietnam is a Southeast Asian country known for its rich history, diverse landscapes, and delicious cuisine. Hanoi and Ho Chi Minh City are its major urban centers, each with a unique character. Ha Long Bay’s limestone karsts and the Mekong Delta’s floating markets are famous geographical highlights. Vietnamese culture is deeply influenced by Confucian values, French colonial heritage, and indigenous traditions.\n",
      "\n",
      "Thailand is a Southeast Asian country famous for its tropical beaches, ornate temples, and bustling street food culture. Bangkok, the capital, is known for its vibrant nightlife and historical sites like the Grand Palace and Wat Arun. Northern Thailand features mountainous landscapes and cultural cities like Chiang Mai, while the south offers world-renowned islands such as Phuket and Koh Samui.\n",
      "\n",
      "Malaysia is a diverse country in Southeast Asia, divided into Peninsular Malaysia and Malaysian Borneo. Kuala Lumpur, the capital, features the iconic Petronas Towers. The country is known for its multicultural society, rainforests, and beautiful islands such as Langkawi. Malaysian cuisine blends Malay, Chinese, and Indian influences, making it one of the most flavorful in the region.\n",
      "\n",
      "Japan is an island nation in East Asia, known for its unique blend of ancient traditions and cutting-edge technology. It has a rich cultural heritage, including tea ceremonies, sumo wrestling, and kabuki theater. Geographically, Japan consists of four main islands and numerous smaller ones, featuring mountains, forests, and a rugged coastline. Mount Fuji is its most iconic peak. Major cities include Tokyo, Kyoto, and Osaka, each offering distinct experiences from historical temples to modern skyscrapers.\n",
      "\n",
      "Question: What are the best Asian cuisine dishes?\n",
      "Answer: The first ever cuisine survey by TripAdvisor's Trip Advisor, TripAdvisor ranked Korea's most unique meal in 2016 according to the three criteria: the food quality, the taste, and the taste of food being eaten on its menu. The score was based on a score from one of eight five criteria: the food quality, the taste, and the food's taste. Korean cuisine is a mixture of both the culinary arts and modern food traditions across the globe.\n",
      "\n",
      "There are 15 food-related restaurants in New Zealand. One restaurant in Australia is a Thai restaurant. The list does not include other Asian places. However, all Asian places rank highly of the list, ranking 9 out of 10 and one out of five from the food-related websites. The list also includes food in its menus. Top five cuisine websites for all regions were ranked from highest to lowest depending on where they are in the year.\n",
      "\n",
      "Question: Do you see Asian food as something you should take seriously in your\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the best Asian cuisine dishes?\"\n",
    "\n",
    "# Use `invoke` instead of `get_relevant_documents`\n",
    "retrieved_docs = retriever.invoke(query)[:1]  # Top-1 document\n",
    "context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "context = truncate_to_max_tokens(context, max_tokens=500)\n",
    "\n",
    "# Use `invoke` instead of `run`\n",
    "response = retrieval_qa.invoke({\"query\": query})\n",
    "print(\"Answer:\", response[\"result\"])  # Access the result via [\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0f772-d006-4b24-85a6-290e605aabb8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sample of chunk with `langchain` [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018fb5fd-b005-425c-b1c0-44eef9d9f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 66, which is longer than the specified 30\n",
      "Created a chunk of size 70, which is longer than the specified 30\n",
      "Created a chunk of size 103, which is longer than the specified 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 4 chunks!\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text = \"Your long document here... Singapore has many amazing restaurants.\\n Bangkok offers the best seafood and seafood from all over the world. \\n Northern Thailand features mountainous landscapes and cultural cities like Chiang Mai, while the south\\n offers world-renowned islands such as Phuket and Koh Samui.\"\n",
    "splitter = CharacterTextSplitter(chunk_size=30, \n",
    "                                 chunk_overlap=10, \n",
    "                                 separator=\"\\n\")\n",
    "chunks = splitter.split_text(text)\n",
    "print(f\"Split into {len(chunks)} chunks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012f5cb4-afa7-49dd-97fa-b26411efb8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Your long document here... Singapore has many amazing restaurants.',\n",
       " 'Bangkok offers the best seafood and seafood from all over the world.',\n",
       " 'Northern Thailand features mountainous landscapes and cultural cities like Chiang Mai, while the south',\n",
       " 'offers world-renowned islands such as Phuket and Koh Samui.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809aadc-d74b-4bae-a4ca-3adb877d1084",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sample of chunk with `langchain` [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5473082e-d3b5-4e22-84aa-debd2d65dc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 15 chunks!\n",
      "Chunk 1: Your long document here...\n",
      "Chunk 2: here... Singapore has many\n",
      "Chunk 3: has many amazing restaurants.\n",
      "Chunk 4: Bangkok offers the best\n",
      "Chunk 5: the best seafood and seafood\n",
      "Chunk 6: seafood from all over the\n",
      "Chunk 7: over the world. Northern\n",
      "Chunk 8: Northern Thailand features\n",
      "Chunk 9: features mountainous\n",
      "Chunk 10: landscapes and cultural cities\n",
      "Chunk 11: cities like Chiang Mai, while\n",
      "Chunk 12: Mai, while the south offers\n",
      "Chunk 13: offers world-renowned islands\n",
      "Chunk 14: islands such as Phuket and Koh\n",
      "Chunk 15: and Koh Samui.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text = \"Your long document here... Singapore has many amazing restaurants. Bangkok offers the best seafood and seafood from all over the world. Northern Thailand features mountainous landscapes and cultural cities like Chiang Mai, while the south offers world-renowned islands such as Phuket and Koh Samui.\"\n",
    "\n",
    "# Specify separator (e.g., space) to force splitting\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=30,\n",
    "    chunk_overlap=10,\n",
    "    separator=\" \"  # Split on spaces\n",
    ")\n",
    "chunks = splitter.split_text(text)\n",
    "print(f\"Split into {len(chunks)} chunks!\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3dee4a-ae1c-46bc-92f4-ba5385f99b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
